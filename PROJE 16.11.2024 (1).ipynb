{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "data_dir = r'C:\\Users\\asha\\project2\\flowers'  \n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "val_dir = os.path.join(data_dir, 'validation')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "flower_types = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "\n",
        "for flower in flower_types:\n",
        "    flower_dir = os.path.join(data_dir, flower)\n",
        "\n",
        "\n",
        "    if os.path.isdir(flower_dir):\n",
        "        images = os.listdir(flower_dir)\n",
        "\n",
        "        \n",
        "        random.shuffle(images)\n",
        "        split_index = int(len(images) * 0.8) \n",
        "        train_images = images[:split_index]\n",
        "        val_images = images[split_index:]\n",
        "\n",
        " \n",
        "        train_flower_dir = os.path.join(train_dir, flower)\n",
        "        os.makedirs(train_flower_dir, exist_ok=True)\n",
        "\n",
        "        for image in train_images:\n",
        "            src_path = os.path.join(flower_dir, image)\n",
        "            dst_path = os.path.join(train_flower_dir, image)\n",
        "            if os.path.exists(src_path):  \n",
        "                try:\n",
        "                    shutil.copy(src_path, dst_path)\n",
        "                except PermissionError:\n",
        "                    print(f\"permison error: {src_path} can't copy.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"error created: {str(e)}\")\n",
        "            else:\n",
        "                print(f\"not excist: {src_path}\")\n",
        "\n",
        "     \n",
        "        val_flower_dir = os.path.join(val_dir, flower)\n",
        "        os.makedirs(val_flower_dir, exist_ok=True)\n",
        "\n",
        "        for image in val_images:\n",
        "            src_path = os.path.join(flower_dir, image)\n",
        "            dst_path = os.path.join(val_flower_dir, image)\n",
        "            if os.path.exists(src_path): \n",
        "                try:\n",
        "                    shutil.copy(src_path, dst_path)\n",
        "                except PermissionError:\n",
        "                    print(f\"permison error: {src_path} can't copy.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"error created: {str(e)}\")\n",
        "            else:\n",
        "                print(f\"not excist: {src_path}\")\n",
        "\n",
        "print(\"Images successfully separated into train and validation folders!\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Train:\")\n",
        "for flower in os.listdir(train_dir):\n",
        "    flower_path = os.path.join(train_dir, flower)\n",
        "    print(f\" - {flower}: {len(os.listdir(flower_path))} image\")\n",
        "\n",
        "\n",
        "print(\"\\nValidation:\")\n",
        "for flower in os.listdir(val_dir):\n",
        "    flower_path = os.path.join(val_dir, flower)\n",
        "    print(f\" - {flower}: {len(os.listdir(flower_path))} image\")\n",
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  \n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  \n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False \n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(len(flower_types), activation='softmax'))  \n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // 32,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // 32,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "\n",
        "model.save('flower_classifier_model.h5')\n",
        "\n",
        "model.summary()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Images successfully separated into train and validation folders!\nTrain:\n - daisy: 764 image\n - dandelion: 1052 image\n - rose: 784 image\n - sunflower: 733 image\n - tulip: 984 image\n\nValidation:\n - daisy: 739 image\n - dandelion: 1019 image\n - rose: 748 image\n - sunflower: 704 image\n - tulip: 941 image\nFound 4317 images belonging to 5 classes.\nFound 4151 images belonging to 5 classes.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "D:\\anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1126s\u001b[0m 8s/step - accuracy: 0.2778 - loss: 6.1672 - val_accuracy: 0.3580 - val_loss: 1.5400\nEpoch 2/10\n\u001b[1m  1/134\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:45\u001b[0m 4s/step - accuracy: 0.4062 - loss: 1.6482"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "D:\\anaconda\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(value)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.4062 - loss: 1.6482 - val_accuracy: 0.3043 - val_loss: 1.5248\nEpoch 3/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m994s\u001b[0m 7s/step - accuracy: 0.4468 - loss: 1.3866 - val_accuracy: 0.4840 - val_loss: 1.2577\nEpoch 4/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.4375 - loss: 1.2294 - val_accuracy: 0.4783 - val_loss: 1.4649\nEpoch 5/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m952s\u001b[0m 7s/step - accuracy: 0.5020 - loss: 1.2345 - val_accuracy: 0.5155 - val_loss: 1.2231\nEpoch 6/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.5938 - loss: 0.9091 - val_accuracy: 0.5652 - val_loss: 1.4691\nEpoch 7/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3288s\u001b[0m 25s/step - accuracy: 0.5009 - loss: 1.2854 - val_accuracy: 0.5848 - val_loss: 1.0450\nEpoch 8/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.6250 - loss: 1.1158 - val_accuracy: 0.5217 - val_loss: 1.2073\nEpoch 9/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2106s\u001b[0m 16s/step - accuracy: 0.5436 - loss: 1.1670 - val_accuracy: 0.5489 - val_loss: 1.1416\nEpoch 10/10\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.4688 - loss: 0.9917 - val_accuracy: 0.6957 - val_loss: 0.8784\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n",
            "text/plain": "\u001b[1mModel: \"sequential\"\u001b[0m\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n",
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m25,690,368\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,285\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,662,673</span> (384.00 MB)\n</pre>\n",
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,662,673\u001b[0m (384.00 MB)\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,691,653</span> (98.01 MB)\n</pre>\n",
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,691,653\u001b[0m (98.01 MB)\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n</pre>\n",
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,383,308</span> (196.01 MB)\n</pre>\n",
            "text/plain": "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m51,383,308\u001b[0m (196.01 MB)\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {},
      "id": "b48b4a46-d346-4d61-a466-303e6a16ca54"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "055cefe9-fbfb-44c1-88a3-cd3964d8eb63"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}